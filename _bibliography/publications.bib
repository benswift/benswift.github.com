
@inproceedings{swiftChasingWindExperience2011a,
  title = {A {{Chasing After}} the {{Wind}}: {{Experience}} in {{Computer}}-Supported {{Group Musicmaking}}},
  eventtitle = {British {{HCI Group Annual Conference}} on {{People}} and {{Computers}}},
  booktitle = {In {{Proceedings}} of "{{When}} Words Fail: {{What}} Can Music Interaction Tell Us about {{HCI}}?" Workshop},
  date = {2011-05-08},
  author = {Swift, Ben and Gardner, Henry and Riddell, Alistair},
  file = {/Users/ben/Documents/Zotero/storage/URQ7F4R2/Swift et al. - 2011 - A Chasing After the Wind Experience in Computer-s.pdf}
}

@unpublished{swiftUntitled2013b,
  venue = {{107 Projects, Redfern, NSW, Australia}},
  title = {Untitled},
  url = {http://www.isea2013.org/events/mume2013/},
  type = {livecoding set},
  eventtitle = {Musical {{Metacreation}} ({{MuMe}}) {{Algorave}} at {{ISEA}} 2013: {{International Symposium}} on {{Electronic Art}}},
  date = {2013-06-15},
  author = {Swift, Ben and Sorensen, Andrew},
  note = {*** Organising Committee ***

Oliver Bown (Design Lab, University of Sydney)
Philippe Pasquier (School of Interactive Arts and Technologies, Simon Fraser University)
Arne Eigenfeldt (School for the Contemporary Arts, Simon Fraser University)

*** Curatorial Committee ***

George Lewis (Department of Music, Columbia University)
Alex McLean (Interdisciplinary Centre for Scientific Research in Music, University of Leeds)
Michael Young (Department of Music, Goldsmiths College, University of London)
Tim Blackwell (Department of Computing, Goldsmiths College, University of London)
Jon McCormack (Centre for Electronic Media Art, Monash University)
Juha van ‘t Zelfde (Viral Radio founder, curator Bimhuis, Musiekgebouw, Amsterdam)
Ivan Zavada (Conservatorium of Music, University of Sydney)
Aengus Martin (Faculty of Engineering, University of Sydney)
Bill Hsu (School of IT, San Francisco State University)}
}

@unpublished{swiftUntitled2008,
  venue = {{ANU School of Art, Canberra, Australia}},
  title = {Untitled},
  type = {livecoding set},
  eventtitle = {Transmissions in {{Sound}}},
  date = {2008-10-15},
  author = {Swift, Ben}
}

@unpublished{swiftUntitled2017a,
  venue = {{National Film and Sound Archive, Canberra}},
  title = {Untitled},
  type = {livecoding set},
  eventtitle = {National {{Science Week}} '17 {{ACT Launch Event}}},
  date = {2017-08-11},
  author = {Swift, Ben}
}

@unpublished{swiftUntitled2018a,
  venue = {{Molo Bar, Australian National University}},
  title = {Untitled},
  type = {livecoding set},
  eventtitle = {National {{Science Week}} '18 {{ACT Launch Event}}},
  date = {2018-08-10},
  author = {Swift, Ben and Browne, Kieran}
}

@unpublished{swiftUntitled2018,
  venue = {{Doughnut Dept., Canberra}},
  title = {Untitled},
  type = {livecoding set},
  eventtitle = {Shirty {{Science Season}} 3 Launch Party},
  date = {2018-08-13},
  author = {Swift, Ben and Browne, Kieran}
}

@unpublished{swiftUntitled2015,
  venue = {{ANU School of Music, Canberra, Australia}},
  title = {Untitled},
  url = {http://www.agac.com.au/event/collected-resonances-3/},
  type = {livecoding set},
  eventtitle = {Collected {{Resonances}}},
  date = {2015-08-26},
  author = {Swift, Ben}
}

@unpublished{swiftUntitled2013a,
  venue = {{ANU School of Art, Canberra, Australia}},
  title = {Untitled},
  type = {livecoding set},
  eventtitle = {Revenant {{Media}}: {{Theremin}} '75 {{Exhibition}}},
  date = {2013-10-25},
  author = {Swift, Ben}
}

@unpublished{swiftUntitled2014a,
  venue = {{Kendall Lane Theatre, New Acton, Canberra}},
  title = {Untitled},
  url = {https://artnotapart.com},
  type = {livecoding set},
  eventtitle = {Art, {{Not Apart}} 2014},
  date = {2014-03-15},
  author = {Swift, Ben and Sko, Torben}
}

@unpublished{swiftUntitled2014c,
  venue = {{Canberra Museum and Gallery}},
  title = {Untitled},
  url = {https://issuu.com/newbestfriend/docs/yah_program2014_issuu},
  type = {livecoding set},
  eventtitle = {You {{Are Here Festival}} -  in Case of Sound: Round One},
  date = {2014-03-15},
  author = {Swift, Ben}
}

@unpublished{swiftUntitled2010,
  venue = {{ANU School of Art, Canberra, Australia}},
  title = {Untitled},
  type = {livecoding set},
  eventtitle = {Beginning-{{Middle}}-{{End Festival}}},
  date = {2010-09-04},
  author = {Swift, Ben}
}

@unpublished{swiftUntitled2018c,
  venue = {{Questacon, Canberra}},
  title = {Untitled},
  type = {livecoding set},
  eventtitle = {Questacon {{Invention Convention Closing Ceremony}}},
  date = {2018-01-19},
  author = {Swift, Ben}
}

@unpublished{swiftUntitled2018b,
  venue = {{Smiths Alternative Bookshop, Canberra}},
  title = {Untitled},
  type = {livecoding set},
  eventtitle = {Soundscapes {{Concert Series}} \#21},
  date = {2018-05-03},
  author = {Swift, Ben}
}

@unpublished{swiftUntitled2015a,
  venue = {{John Curtin School of Medical Research, Canberra}},
  title = {Untitled},
  type = {livecoding set},
  eventtitle = {Innovation {{ACT}} 2015 {{Launch Party}}},
  date = {2015-08-12},
  author = {Swift, Ben}
}

@unpublished{swiftUntitled2013,
  venue = {{Mt Stromlo Observatory, Canberra}},
  title = {Untitled},
  type = {livecoding set},
  eventtitle = {{{ICOMOS}} 2013: {{International Council}} on {{Monuments}} and {{Sites}}},
  date = {2013-11-02},
  author = {Swift, Ben}
}

@unpublished{swiftUntitled2016,
  venue = {{National Museum of Australia, Canberra}},
  title = {Untitled},
  type = {livecoding set},
  eventtitle = {{{ANU CECS}} 45th {{Anniversary Celebration}}},
  date = {2016-10-22},
  author = {Swift, Ben}
}

@unpublished{swiftUntitled2014b,
  venue = {{Drill Hall Gallery, Canberra}},
  title = {Untitled},
  type = {livecoding set},
  eventtitle = {John {{Hosking Farewell Reception}}},
  date = {2014-05-28},
  author = {Swift, Ben}
}

@unpublished{swiftUntitled2009,
  venue = {{Queensland University of Technology}},
  title = {Untitled},
  type = {livecoding set},
  eventtitle = {{{ACMC}} '09: {{Australasian Computer Music Conference}}},
  date = {2009-07-03},
  author = {Swift, Ben}
}

@unpublished{swiftUntitled2017,
  venue = {{Australian National University, Canberra}},
  title = {Untitled},
  type = {livecoding set},
  eventtitle = {Australian {{Informatics Olympiad Program}}},
  date = {2017-12-08},
  author = {Swift, Ben}
}

@unpublished{swiftUntitled2014,
  venue = {{Victorian College of the Arts, Melbourne}},
  title = {Untitled},
  type = {livecoding set},
  eventtitle = {{{ACMC}} '14: {{Australasian Computer Music Conference}}},
  date = {2014-07-10},
  author = {Swift, Ben and Sorensen, Andrew}
}

@article{swiftImpishGrooves2011,
  title = {Impish {{Grooves}}},
  volume = {35},
  url = {http://www.mitpressjournals.org/doi/abs/10.1162/COMJ_e_00098},
  number = {4},
  journaltitle = {Computer Music Journal},
  shortjournal = {Computer Music Journal},
  date = {2011-01-01},
  pages = {119-137},
  author = {Swift, Ben}
}

@inproceedings{swiftDistributedPerformanceLive2009a,
  title = {Distributed {{Performance}} in {{Live Coding}}},
  eventtitle = {{{ACMC}} '09: {{Proceedings}} of the {{Australasian Computer Music Conference}}},
  date = {2009-07},
  pages = {1--6},
  author = {Swift, Ben and Gardner, Henry J and Riddell, Alistair}
}

@incollection{swiftChasingFeelingExperience2013a,
  location = {{London}},
  title = {Chasing a {{Feeling}}: {{Experience}} in {{Computer Supported Jamming}}},
  isbn = {978-1-4471-2990-5},
  url = {https://doi.org/10.1007/978-1-4471-2990-5_5},
  abstract = {Improvisational group music-making, informally known as ‘jamming’, has its own cultures and conventions of musical interaction. One characteristic of this interaction is the primacy of the experience over the musical artefact—in some sense the sound created is not as important as the feeling of being ‘in the groove’. As computing devices infiltrate creative, open-ended task domains, what can Human-Computer Interaction (HCI) learn from jamming? How do we design systems where the goal is not an artefact but a felt experience? This chapter examines these issues in light of an experiment involving ‘Viscotheque’, a novel group music-making environment based on the iPhone.},
  booktitle = {Music and {{Human}}-{{Computer Interaction}}},
  publisher = {{Springer London}},
  date = {2013},
  pages = {85-99},
  author = {Swift, Ben},
  editor = {Holland, Simon and Wilkie, Katie and Mulholland, Paul and Seago, Allan},
  doi = {10.1007/978-1-4471-2990-5_5}
}

@inproceedings{swiftVisualCodeAnnotations2013a,
  title = {Visual Code Annotations for Cyberphysical Programming},
  doi = {10.1109/LIVE.2013.6617345},
  abstract = {User interfaces for source code editing are a crucial component in any software development environment, and in many editors visual annotations (overlaid on the textual source code) are used to provide important contextual information to the programmer. This paper focuses on the real-time programming activity of `cyberphysical' programming, and considers the type of visual annotations which may be helpful in this programming context.},
  eventtitle = {2013 1st {{International Workshop}} on {{Live Programming}} ({{LIVE}})},
  booktitle = {2013 1st {{International Workshop}} on {{Live Programming}} ({{LIVE}})},
  date = {2013-05},
  pages = {27-30},
  keywords = {Context,contextual information,cyberphysical programming,interactive programming,Production,program compilers,Programming,programming context,real-time programming activity,Robots,Software,software development environment,source code editing,System-on-chip,textual source code,user interfaces,visual code annotations,visual programming,Visualization},
  author = {Swift, B. and Sorensen, A. and Gardner, H. and Hosking, J.},
  file = {/Users/ben/Documents/Zotero/storage/QNMKPMGZ/Swift et al. - 2013 - Visual code annotations for cyberphysical programm.pdf;/Users/ben/Documents/Zotero/storage/J6VY85SK/6617345.html}
}

@inproceedings{swiftEngagementNetworksSocial2010a,
  location = {{New York, NY, USA}},
  title = {Engagement {{Networks}} in {{Social Music}}-Making},
  isbn = {978-1-4503-0502-0},
  url = {http://doi.acm.org/10.1145/1952222.1952244},
  doi = {10.1145/1952222.1952244},
  abstract = {Social music-making systems offer the possibility of accessible and engaging group experiences. In this paper we explore questions concerning the notion of 'engagement' in social music-making. In a recent user study of Viscotheque, an iPhone-based environment for group musical creativity, three different types of engagement were observed: individual, unilateral and bilateral. These results indicate that network-based approaches may be useful in analysing engagement relationships amongst participants in group music-making.},
  booktitle = {Proceedings of the {{22Nd Conference}} of the {{Computer}}-{{Human Interaction Special Interest Group}} of {{Australia}} on {{Computer}}-{{Human Interaction}}},
  series = {{{OZCHI}} '10},
  publisher = {{ACM}},
  urldate = {2019-01-23},
  date = {2010},
  pages = {104--111},
  keywords = {engagement,mutual},
  author = {Swift, Ben and Gardner, Henry and Riddell, Alistair},
  file = {/Users/ben/Documents/Zotero/storage/K7CQUSEK/Swift et al. - 2010 - Engagement Networks in Social Music-making.pdf}
}

@inproceedings{martinExploringPercussiveGesture2014a,
  location = {{New York, NY, USA}},
  title = {Exploring {{Percussive Gesture}} on {{iPads}} with {{Ensemble Metatone}}},
  isbn = {978-1-4503-2473-1},
  url = {http://doi.acm.org/10.1145/2556288.2557226},
  doi = {10.1145/2556288.2557226},
  abstract = {Percussionists are unique among western classical instrumentalists in that their artistic practice is defined by an approach to interaction rather than their instruments. While percussionists are accustomed to exploring non-traditional objects to create music, these objects have yet to encompass touch-screen computing devices to any great extent. The proliferation and popularity of these devices now presents an opportunity to explore their use in combining computer-generated sound together with percussive interaction in a musical ensemble. This paper examines Ensemble Metatone, a group formed to explore the "infiltration" of iPad-based musical instruments into a free-improvisation percussion ensemble. We discuss the design approach for two different iPad percussion instruments and the methodology for exploring them with the group over a series of rehearsals and performances. Qualitative analysis of discussions throughout this process shows that the musicians developed a vocabulary of gestures and musical interactions to make musical sense of these new instruments.},
  booktitle = {Proceedings of the {{SIGCHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  series = {{{CHI}} '14},
  publisher = {{ACM}},
  urldate = {2019-01-23},
  date = {2014},
  pages = {1025--1028},
  keywords = {expression,gesture,multitouch,music,percussion,user experience},
  author = {Martin, Charles and Gardner, Henry and Swift, Ben},
  file = {/Users/ben/Documents/Zotero/storage/GQWAWBLD/Martin et al. - 2014 - Exploring Percussive Gesture on iPads with Ensembl.pdf}
}

@article{sorensenManyMeaningsLive2014a,
  title = {The {{Many Meanings}} of {{Live Coding}}},
  volume = {38},
  issn = {0148-9267},
  url = {https://doi.org/10.1162/COMJ_a_00230},
  doi = {10.1162/COMJ_a_00230},
  abstract = {The ten-year anniversary of TOPLAP presents a unique opportunity for reflection and introspection. In this essay we ask the question, what is the meaning of live coding? Our goal is not to answer this question, in absolute terms, but rather to attempt to unpack some of live coding's many meanings. Our hope is that by exploring some of the formal, embodied, and cultural meanings surrounding live-coding practice, we may help to stimulate a conversation that will resonate within the live-coding community for the next ten years.},
  number = {1},
  journaltitle = {Computer Music Journal},
  shortjournal = {Computer Music Journal},
  urldate = {2019-01-23},
  date = {2014-03-01},
  pages = {65-76},
  author = {Sorensen, Andrew and Swift, Ben and Riddell, Alistair},
  file = {/Users/ben/Documents/Zotero/storage/7585EBPS/COMJ_a_00230.html}
}

@inproceedings{swiftCodingLivecoding2014a,
  location = {{New York, NY, USA}},
  title = {Coding {{Livecoding}}},
  isbn = {978-1-4503-2473-1},
  url = {http://doi.acm.org/10.1145/2556288.2557049},
  doi = {10.1145/2556288.2557049},
  abstract = {Livecoding is an artistic programming practice in which an artist's low-level interaction can be observed with sufficiently high fidelity to allow for transcription and analysis. This paper presents the first reported "coding" of livecoding videos. From an identified corpus of videos available on the web, we coded performances of two different livecoding artists, recording both the (textual) programming edit events and the musical effect of these edits. Our analysis includes a novel, transition-matrix visualisation of the textual and musical dimensions of this data to create a "performer fingerprint". We show how detailed transcriptions of livecoding videos can be made which, we hope, will provide a foundation for further research into describing and understanding livecoding.},
  booktitle = {Proceedings of the {{SIGCHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  series = {{{CHI}} '14},
  publisher = {{ACM}},
  urldate = {2019-01-23},
  date = {2014},
  pages = {1021--1024},
  keywords = {creativity support tools,end-user programming},
  author = {Swift, Ben and Sorensen, Andrew and Martin, Michael and Gardner, Henry},
  file = {/Users/ben/Documents/Zotero/storage/8XGUHV48/Swift et al. - 2014 - Coding Livecoding.pdf}
}

@article{wuTextureAnalysis3D2015,
  title = {Texture Analysis of the {{3D}} Collagen Network and Automatic Classification of the Physiology of Articular Cartilage {{AU}}  - {{Duan}}, {{Xiaojuan}}},
  volume = {18},
  issn = {1025-5842},
  url = {https://doi.org/10.1080/10255842.2013.864284},
  doi = {10.1080/10255842.2013.864284},
  number = {9},
  journaltitle = {Computer Methods in Biomechanics and Biomedical Engineering},
  shortjournal = {Computer Methods in Biomechanics and Biomedical Engineering},
  date = {2015-07-04},
  pages = {931-943},
  author = {Wu, Jianping and Swift, Benjamin and Kirk, Thomas Brett},
  file = {/Users/ben/Documents/Zotero/storage/2D2IABJ8/Wu et al. - 2015 - Texture analysis of the 3D collagen network and au.pdf}
}

@inproceedings{martinIntelligentAgentsNetworked2016a,
  location = {{New York, NY, USA}},
  title = {Intelligent {{Agents}} and {{Networked Buttons Improve Free}}-{{Improvised Ensemble Music}}-{{Making}} on {{Touch}}-{{Screens}}},
  isbn = {978-1-4503-3362-7},
  url = {http://doi.acm.org/10.1145/2858036.2858269},
  doi = {10.1145/2858036.2858269},
  abstract = {We present the results of two controlled studies of free-improvised ensemble music-making on touch-screens. In our system, updates to an interface of harmonically-selected pitches are broadcast to every touch-screen in response to either a performer pressing a GUI button, or to interventions from an intelligent agent. In our first study, analysis of survey results and performance data indicated significant effects of the button on performer preference, but of the agent on performance length. In the second follow-up study, a mixed-initiative interface, where the presence of the button was interlaced with agent interventions, was developed to leverage both approaches. Comparison of this mixed-initiative interface with the always-on button-plus-agent condition of the first study demonstrated significant preferences for the former. The different approaches were found to shape the creative interactions that take place. Overall, this research offers evidence that an intelligent agent and a networked GUI both improve aspects of improvised ensemble music-making.},
  booktitle = {Proceedings of the 2016 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  series = {{{CHI}} '16},
  publisher = {{ACM}},
  urldate = {2019-01-23},
  date = {2016},
  pages = {2295--2306},
  keywords = {agent,collaborative interaction,creativity support tools,design,mobile music},
  author = {Martin, Charles and Gardner, Henry and Swift, Ben and Martin, Michael},
  file = {/Users/ben/Documents/Zotero/storage/QFRX2GJP/Martin et al. - 2016 - Intelligent Agents and Networked Buttons Improve F.pdf}
}

@inproceedings{martinMetatravelsMetalonsdaleIpad2014a,
  location = {{New York, NY, USA}},
  title = {Metatravels and {{Metalonsdale}}: {{Ipad Apps}} for {{Percussive Improvisation}}},
  isbn = {978-1-4503-2474-8},
  url = {http://doi.acm.org/10.1145/2559206.2574805},
  doi = {10.1145/2559206.2574805},
  shorttitle = {Metatravels and {{Metalonsdale}}},
  abstract = {Percussionists are unique among instrumentalists in that their artistic practice is defined by an approach to interaction rather than their instruments. While percussionists are accustomed to exploring non-traditional objects to create music, these objects have yet to encompass touch-screen computing devices to any great extent. The proliferation and popularity of these devices now presents an opportunity to explore their use in combining computer-generated sound together with percussive interaction in a musical ensemble. This interactivity demonstration presents two iPad-instruments developed in collaboration with Ensemble Metatone, a group formed to explore the "infiltration" of iPad apps into a free-improvisation percussion ensemble. The apps encourage the performers' exploration through percussive gestures and use network features to support cohesive improvisation.},
  booktitle = {{{CHI}} '14 {{Extended Abstracts}} on {{Human Factors}} in {{Computing Systems}}},
  series = {{{CHI EA}} '14},
  publisher = {{ACM}},
  urldate = {2019-01-23},
  date = {2014},
  pages = {547--550},
  keywords = {artistic research,expression,gesture,multitouch,music,percussion,user experience},
  author = {Martin, Charles and Gardner, Henry and Swift, Ben},
  file = {/Users/ben/Documents/Zotero/storage/7RVXPLGR/Martin et al. - 2014 - Metatravels and Metalonsdale Ipad Apps for Percus.pdf}
}

@inproceedings{swiftBecomingsoundAffectAssemblage2012a,
  location = {{New York, NY, USA}},
  title = {Becoming-Sound: {{Affect}} and {{Assemblage}} in {{Improvisational Digital Music Making}}},
  isbn = {978-1-4503-1015-4},
  url = {http://doi.acm.org/10.1145/2207676.2208315},
  doi = {10.1145/2207676.2208315},
  shorttitle = {Becoming-Sound},
  abstract = {The concepts of affect and assemblage proposed by thinkers such as Gilles Deleuze and Brian Massumi can help us to understand the interaction between users and artefacts in interactive systems, particularly in the context of computer-supported improvisation and creativity. In this paper I provide an introduction to affect and assemblage theory for HCI practitioners. I then use a case study of Viscotheque, an iOS-based interface for group musical collaboration, to demonstrate the application of affective analysis in making sense of improvisational group music making.},
  booktitle = {Proceedings of the {{SIGCHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  series = {{{CHI}} '12},
  publisher = {{ACM}},
  urldate = {2019-01-23},
  date = {2012},
  pages = {1815--1824},
  keywords = {affect,assemblage,improvisation,music making},
  author = {Swift, Benjamin},
  file = {/Users/ben/Documents/Zotero/storage/GJ87V5RI/Swift - 2012 - Becoming-sound Affect and Assemblage in Improvisa.pdf}
}

@inproceedings{swiftMindmodulatedMusicMind2007,
  location = {{New York, NY, USA}},
  title = {Mind-Modulated {{Music}} in the {{Mind Attention Interface}}},
  isbn = {978-1-59593-872-5},
  url = {http://doi.acm.org/10.1145/1324892.1324907},
  doi = {10.1145/1324892.1324907},
  abstract = {A recent study of electroencephalogram (EEG) activity associated with musical cognition has suggested a correlate for the amount of active musical processing taking place in the brains of musicians. Using a version of this measure, we have built a new brain computer interface which harnesses the "natural" brain activity of musicians to mold and modulate music as it is being composed and played. This computer music instrument is part of a system, the Mind Attention Interface, which provides an interface to a virtual reality theatre using measures of a participant's EEG, eye-gaze and head position. The theatre itself, and its spatialised sound system, closes a feedback loop through the mind of the participant.},
  booktitle = {Proceedings of the 19th {{Australasian Conference}} on {{Computer}}-{{Human Interaction}}: {{Entertaining User Interfaces}}},
  series = {{{OZCHI}} '07},
  publisher = {{ACM}},
  urldate = {2019-01-23},
  date = {2007},
  pages = {83--86},
  keywords = {brain computer interface,computer music,EEG,functional connectivity},
  author = {Swift, Ben and Sheridan, James and Zhen, Yang and Gardner, Henry J.},
  file = {/Users/ben/Documents/Zotero/storage/P7NEGBWQ/Swift et al. - 2007 - Mind-modulated Music in the Mind Attention Interfa.pdf}
}

@article{wuHighresolutionStudy3D2017,
  langid = {french},
  title = {High-resolution study of the 3D collagen fibrillary matrix of Achilles tendons without tissue labelling and dehydrating},
  volume = {266},
  issn = {1365-2818},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/jmi.12537},
  doi = {10.1111/jmi.12537},
  abstract = {Knowledge of the collagen structure of an Achilles tendon is critical to comprehend the physiology, biomechanics, homeostasis and remodelling of the tissue. Despite intensive studies, there are still uncertainties regarding the microstructure. The majority of studies have examined the longitudinally arranged collagen fibrils as they are primarily attributed to the principal tensile strength of the tendon. Few studies have considered the structural integrity of the entire three-dimensional (3D) collagen meshwork, and how the longitudinal collagen fibrils are integrated as a strong unit in a 3D domain to provide the tendons with the essential tensile properties. Using second harmonic generation imaging, a 3D imaging technique was developed and used to study the 3D collagen matrix in the midportion of Achilles tendons without tissue labelling and dehydration. Therefore, the 3D collagen structure is presented in a condition closely representative of the in vivo status. Atomic force microscopy studies have confirmed that second harmonic generation reveals the internal collagen matrix of tendons in 3D at a fibril level. Achilles tendons primarily contain longitudinal collagen fibrils that braid spatially into a dense rope-like collagen meshwork and are encapsulated or wound tightly by the oblique collagen fibrils emanating from the epitenon region. The arrangement of the collagen fibrils provides the longitudinal fibrils with essential structural integrity and endows the tendon with the unique mechanical function for withstanding tensile stresses. A novel 3D microscopic method has been developed to examine the 3D collagen microstructure of tendons without tissue dehydrating and labelling. The study also provides new knowledge about the collagen microstructure in an Achilles tendon, which enables understanding of the function of the tissue. The knowledge may be important for applying surgical and tissue engineering techniques to tendon reconstruction.},
  number = {3},
  journaltitle = {Journal of Microscopy},
  urldate = {2019-01-23},
  date = {2017},
  pages = {273-287},
  keywords = {3D collagen structure,Achilles tendons,computer imaging analysis,SHG imaging},
  author = {Wu, Jian-Ping and Swift, Benjamin John and Becker, Thomas and Squelch, Andrew and Wang, Allan and Zheng, Yong-Chang and Zhao, Xuelin and Xu, Jiake and Xue, Wei and Zheng, Minghao and Lloyd, David and Kirk, Thomas Brett},
  file = {/Users/ben/Documents/Zotero/storage/GHQSAZG2/Wu et al. - 2017 - High-resolution study of the 3D collagen fibrillar.pdf;/Users/ben/Documents/Zotero/storage/7CKAVRBD/jmi.html}
}

@article{chrzeszczykInfiniCloudDistributingHigh2016a,
  langid = {english},
  title = {{{InfiniCloud}} 2.0: Distributing {{High Performance Computing}} across Continents.},
  volume = {3},
  issn = {2313-8734},
  url = {http://superfri.org/superfri/article/view/95},
  doi = {10.14529/jsfi160204},
  shorttitle = {{{InfiniCloud}} 2.0},
  abstract = {InfiniCloud 2.0 is World’s first native InfiniBand High Performance Cloud distributed across four continents, spanning Asia, Australia, Europe and North America. The project provides researchers with instant access to computational, storage and network resources distributed around the globe. These resources are then used to build a geographically distributed, virtual supercomputer, complete with globally-accessible parallel file system and job scheduling.This paper describes high level design and the implementation details of InfiniCloud 2.0. A gene sequencing pipeline as well as plasma physics simulation code are used to demonstrate system’s capabilities.},
  number = {2},
  journaltitle = {Supercomputing Frontiers and Innovations},
  urldate = {2019-01-23},
  date = {2016-06-27},
  pages = {54-71-71},
  author = {Chrzeszczyk, Jakub and Howard, Andrew and Chrzeszczyk, Andrzej and Swift, Ben and Davis, Peter and Low, Jonathan and Tan, Tin Wee and Ban, Kenneth},
  file = {/Users/ben/Documents/Zotero/storage/Q6PTUNLN/Chrzeszczyk et al. - 2016 - InfiniCloud 2.0 distributing High Performance Com.pdf;/Users/ben/Documents/Zotero/storage/RAHB47KC/95.html}
}

@article{swiftLiveProgrammingScientific2016a,
  langid = {english},
  title = {Live {{Programming}} in {{Scientific Simulation}}},
  volume = {2},
  issn = {2313-8734},
  url = {http://superfri.org/superfri/article/view/72},
  doi = {10.14529/jsfi150401},
  abstract = {We demonstrate that a live-programming environment can be used to harness and add run-time interactivity to scientific simulation codes. Through a set of examples using a Particle-In-Cell (PIC) simulation framework we show how the real-time, human-in-the-loop interactivity of live programming can be incorporated into a traditional, “offline”, development workflow. We discuss how live programming tools and techniques can be productively integrated into the existing HPC landscape to increase productivity and enhance exploration and discovery.},
  number = {4},
  journaltitle = {Supercomputing Frontiers and Innovations},
  urldate = {2019-01-23},
  date = {2016-03-07},
  pages = {4-15-15},
  author = {Swift, Ben and Sorensen, Andrew and Gardner, Henry and Davis, Peter and Decyk, Viktor K.},
  file = {/Users/ben/Documents/Zotero/storage/IGLQLS6W/Swift et al. - 2016 - Live Programming in Scientific Simulation.pdf;/Users/ben/Documents/Zotero/storage/XRDPCVV9/72.html}
}

@incollection{browneCriticalChallengesVisual2018,
  langid = {english},
  location = {{Cham}},
  title = {Critical {{Challenges}} for the {{Visual Representation}} of {{Deep Neural Networks}}},
  isbn = {978-3-319-90403-0},
  url = {https://doi.org/10.1007/978-3-319-90403-0_7},
  abstract = {Artificial neural networks have proved successful in a broad range of applications over the last decade. However, there remain significant concerns about their interpretability. Visual representation is one way researchers are attempting to make sense of these models and their behaviour. The representation of neural networks raises questions which cross disciplinary boundaries. This chapter draws on a growing collection of interdisciplinary scholarship regarding neural networks. We present six case studies in the visual representation of neural networks and examine the particular representational challenges posed by these algorithms. Finally we summarise the ideas raised in the case studies as a set of takeaways for researchers engaging in this area.},
  booktitle = {Human and {{Machine Learning}}: {{Visible}}, {{Explainable}}, {{Trustworthy}} and {{Transparent}}},
  series = {Human–{{Computer Interaction Series}}},
  publisher = {{Springer International Publishing}},
  urldate = {2019-01-23},
  date = {2018},
  pages = {119-136},
  author = {Browne, Kieran and Swift, Ben and Gardner, Henry},
  editor = {Zhou, Jianlong and Chen, Fang},
  doi = {10.1007/978-3-319-90403-0_7}
}

@inproceedings{browneOtherSideAlgorithm2018,
  location = {{New York, NY, USA}},
  title = {The {{Other Side}}: {{Algorithm As Ritual}} in {{Artificial Intelligence}}},
  isbn = {978-1-4503-5621-3},
  url = {http://doi.acm.org/10.1145/3170427.3188404},
  doi = {10.1145/3170427.3188404},
  shorttitle = {The {{Other Side}}},
  abstract = {Our cultural and scientific understandings of neural networks are built on a set of philosophical ideas which might turn out to be superstitions. Drawing on methodologies of defamiliarisation and performance art which have been adopted by HCI, we present an analog apparatus for the ritualistic performance of neural network algorithms. The apparatus draws on the interaction modes of the Ouija board to provide a system which involves the user in the computation. By recontextualising neural computation, the work creates critical distance with which to examine the philosophical and cultural assumptions embedded in our conception of AI.},
  booktitle = {Extended {{Abstracts}} of the 2018 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  series = {{{CHI EA}} '18},
  publisher = {{ACM}},
  urldate = {2019-01-23},
  date = {2018},
  pages = {alt11:1--alt11:9},
  keywords = {defamiliarisation,neural networks,performance art,ritual,séance},
  author = {Browne, Kieran and Swift, Ben},
  file = {/Users/ben/Documents/Zotero/storage/ZJLBQ7DP/Browne and Swift - 2018 - The Other Side Algorithm As Ritual in Artificial .pdf}
}

@inproceedings{purcellVisualisingLiveCoding2014a,
  location = {{New York, NY, USA}},
  title = {Visualising a {{Live Coding Arts Process}}},
  isbn = {978-1-4503-0653-9},
  url = {http://doi.acm.org/10.1145/2686612.2686634},
  doi = {10.1145/2686612.2686634},
  abstract = {This paper describes an empirical study of source code visualisation as a means to communicate the programming process in "live coding" computer music performances. Following an exploratory field study of a live-coding performance at an arts festival, two different interaction-driven visualisation techniques were incorporated into a live coding system. We then performed a more controlled laboratory study to evaluate the visualisations' contributions to the audience experience, with emphasis on the (self-reported) experiential dimensions of understanding and enjoyment. Both software visualisation techniques enhanced audience enjoyment, while the effect on audience understanding was more complex. We conclude by suggesting how these visualisation techniques may be used to enhance the audience experience of live coding.},
  booktitle = {Proceedings of the 26th {{Australian Computer}}-{{Human Interaction Conference}} on {{Designing Futures}}: {{The Future}} of {{Design}}},
  series = {{{OzCHI}} '14},
  publisher = {{ACM}},
  urldate = {2019-01-23},
  date = {2014},
  pages = {141--144},
  keywords = {live coding,musical performance,software visualisation},
  author = {Purcell, Arrian and Gardner, Henry and Swift, Ben},
  file = {/Users/ben/Documents/Zotero/storage/Q2HB99PG/Purcell et al. - 2014 - Visualising a Live Coding Arts Process.pdf}
}

@inproceedings{martinTrackingEnsemblePerformance2015,
  title = {Tracking Ensemble Performance on Touch-Screens with Gesture Classification and Transition Matrices.},
  booktitle = {{{NIME}}},
  date = {2015},
  pages = {359-364},
  author = {Martin, Charles and Gardner, Henry J. and Swift, Ben},
  file = {/Users/ben/Documents/Zotero/storage/4BP755NV/Martin et al. - 2015 - Tracking ensemble performance on touch-screens wit.pdf}
}

@inproceedings{martinMusic18Performances2015a,
  title = {Music of 18 Performances: {{Evaluating}} Apps and Agents with Free Improvisation},
  isbn = {1448-7780},
  booktitle = {Proceedings of the 2015 {{Annual Conference}} of the {{Australasian Computer Music Association}}},
  publisher = {{The Australasian Computer Music Association}},
  date = {2015},
  author = {Martin, Charles and Gardner, Henry and Swift, Ben and Martin, Michael},
  file = {/Users/ben/Documents/Zotero/storage/S8N62FYD/Martin et al. - 2015 - Music of 18 performances Evaluating apps and agen.pdf}
}

@inproceedings{swiftNetworkedLivecodingVL2014,
  title = {Networked Livecoding at {{VL}}/{{HCC}} 2013},
  isbn = {978-1-4799-4035-6},
  url = {doi.ieeecomputersociety.org/10.1109/VLHCC.2014.6883065},
  doi = {10.1109/VLHCC.2014.6883065},
  abstract = {Network connectivity offers the potential for a group of musicians to play together over the network. This paper describes a trans-Atlantic networked musical livecoding performance between Andrew Sorensen in Germany (at the Schloss Daghstuhl conference on Collaboration and Learning through Live Coding) and Ben Swift in San Jose (at YL/HCC) in September 2013. In this paper we describe the infrastructure developed to enable this performance.},
  booktitle = {2014 {{IEEE Symposium}} on {{Visual Languages}} and {{Human}}-{{Centric Computing}} ({{VL}}/{{HCC}})({{VLHCC}})},
  urldate = {2019-01-23},
  date = {2014-07},
  pages = {221-222},
  keywords = {Australia,Bandwidth,Collaboration,Computer architecture,Educational institutions,Encoding,Servers},
  author = {Swift, B. and Gardner, H. and Sorensen, A.},
  file = {/Users/ben/Documents/Zotero/storage/ZQYYUYDI/06883065-abs.html}
}


